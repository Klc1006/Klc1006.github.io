<!DOCTYPE html>
<html lang="">
    <!-- title -->


    

<!-- keywords -->



<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="author" content="Klc">
    <meta name="renderer" content="webkit">
    <meta name="copyright" content="Klc">
    
        <meta name="keywords" content="hexo,hexo-theme,hexo-blog">
    
    <meta name="description" content="">
    <meta name="description" content="状态价值函数\(V_{\pi}\)和动作价值函数\(Q_{\pi}\)的关系  状态价值函数:从状态\(s\)出发遵循策略\(\pi\)能获得的期望回报 \[ \begin{aligned}     V_{\pi}(s)&amp;&#x3D;\mathbb E [G_{t}|S_{t}&#x3D;s]\\     &amp;&#x3D;\mathbb E [R_{t+1}+\gamma G_{t+1}|S_{t}&#x3D;">
<meta property="og:type" content="article">
<meta property="og:title" content="【RL】PPO以及更新神经网络RNN">
<meta property="og:url" content="https://klc1006.github.io/2023/03/15/%E3%80%90RL%E3%80%91PPO/index.html">
<meta property="og:site_name">
<meta property="og:description" content="状态价值函数\(V_{\pi}\)和动作价值函数\(Q_{\pi}\)的关系  状态价值函数:从状态\(s\)出发遵循策略\(\pi\)能获得的期望回报 \[ \begin{aligned}     V_{\pi}(s)&amp;&#x3D;\mathbb E [G_{t}|S_{t}&#x3D;s]\\     &amp;&#x3D;\mathbb E [R_{t+1}+\gamma G_{t+1}|S_{t}&#x3D;">
<meta property="og:locale">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/6ca0c2b4b623c690c60a749dc1b21291.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/756685e2f07b494b99bc97f4ce0f4bf9.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/1798baf5dba54e21a19508e82d407a8a.png">
<meta property="article:published_time" content="2023-03-15T09:02:53.113Z">
<meta property="article:modified_time" content="2023-03-16T12:39:57.069Z">
<meta property="article:author" content="Klc">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://img-blog.csdnimg.cn/img_convert/6ca0c2b4b623c690c60a749dc1b21291.png">
    <meta http-equiv="Cache-control" content="no-cache">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <link rel="icon" href="/avatar/%E9%BC%A0%E9%BC%A0.jpg">
    
    <title>【RL】PPO以及更新神经网络RNN · PityBug&#39;s Studio</title>
    <!-- /*! loadCSS. [c]2017 Filament Group, Inc. MIT License */
/* This file is meant as a standalone workflow for
- testing support for link[rel=preload]
- enabling async CSS loading in browsers that do not support rel=preload
- applying rel preload css once loaded, whether supported or not.
*/ -->
<script>
    (function (w) {
        'use strict'
        // rel=preload support test
        if (!w.loadCSS) {
            w.loadCSS = function () {}
        }
        // define on the loadCSS obj
        var rp = (loadCSS.relpreload = {})
        // rel=preload feature support test
        // runs once and returns a function for compat purposes
        rp.support = (function () {
            var ret
            try {
                ret = w.document.createElement('link').relList.supports('preload')
            } catch (e) {
                ret = false
            }
            return function () {
                return ret
            }
        })()

        // if preload isn't supported, get an asynchronous load by using a non-matching media attribute
        // then change that media back to its intended value on load
        rp.bindMediaToggle = function (link) {
            // remember existing media attr for ultimate state, or default to 'all'
            var finalMedia = link.media || 'all'

            function enableStylesheet() {
                link.media = finalMedia
            }

            // bind load handlers to enable media
            if (link.addEventListener) {
                link.addEventListener('load', enableStylesheet)
            } else if (link.attachEvent) {
                link.attachEvent('onload', enableStylesheet)
            }

            // Set rel and non-applicable media type to start an async request
            // note: timeout allows this to happen async to let rendering continue in IE
            setTimeout(function () {
                link.rel = 'stylesheet'
                link.media = 'only x'
            })
            // also enable media after 3 seconds,
            // which will catch very old browsers (android 2.x, old firefox) that don't support onload on link
            setTimeout(enableStylesheet, 3000)
        }

        // loop through link elements in DOM
        rp.poly = function () {
            // double check this to prevent external calls from running
            if (rp.support()) {
                return
            }
            var links = w.document.getElementsByTagName('link')
            for (var i = 0; i < links.length; i++) {
                var link = links[i]
                // qualify links to those with rel=preload and as=style attrs
                if (
                    link.rel === 'preload' &&
                    link.getAttribute('as') === 'style' &&
                    !link.getAttribute('data-loadcss')
                ) {
                    // prevent rerunning on link
                    link.setAttribute('data-loadcss', true)
                    // bind listeners to toggle media back
                    rp.bindMediaToggle(link)
                }
            }
        }

        // if unsupported, run the polyfill
        if (!rp.support()) {
            // run once at least
            rp.poly()

            // rerun poly on an interval until onload
            var run = w.setInterval(rp.poly, 500)
            if (w.addEventListener) {
                w.addEventListener('load', function () {
                    rp.poly()
                    w.clearInterval(run)
                })
            } else if (w.attachEvent) {
                w.attachEvent('onload', function () {
                    rp.poly()
                    w.clearInterval(run)
                })
            }
        }

        // commonjs
        if (typeof exports !== 'undefined') {
            exports.loadCSS = loadCSS
        } else {
            w.loadCSS = loadCSS
        }
    })(typeof global !== 'undefined' ? global : this)
</script>

    <style type="text/css">
    @font-face {
        font-family: 'Oswald-Regular';
        src: url("/font/Oswald-Regular.ttf");
    }

    body {
        margin: 0;
    }

    header,
    footer,
    .back-top,
    .sidebar,
    .container,
    .site-intro-meta,
    .toc-wrapper {
        display: none;
    }

    .site-intro {
        position: relative;
        z-index: 3;
        width: 100%;
        /* height: 50vh; */
        overflow: hidden;
    }

    .site-intro-placeholder {
        position: absolute;
        z-index: -2;
        top: 0;
        left: 0;
        width: calc(100% + 300px);
        height: 100%;
        background: repeating-linear-gradient(-45deg, #444 0, #444 80px, #333 80px, #333 160px);
        background-position: center center;
        transform: translate3d(-226px, 0, 0);
        animation: gradient-move 2.5s ease-out 0s infinite;
    }

    @keyframes gradient-move {
        0% {
            transform: translate3d(-226px, 0, 0);
        }
        100% {
            transform: translate3d(0, 0, 0);
        }
    }
</style>

    <link rel="preload" href="/css/style.css?v=20211217" as="style" onload="this.onload=null;this.rel='stylesheet'">
    <link rel="preload" href="/css/dark.css?v=20211217" as="style">
    <link rel="stylesheet" href="/css/dark.css">
    <link rel="stylesheet" href="/css/mobile.css?v=20211217" media="(max-width: 960px)">
    <link rel="preload" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
    <link rel="preload" href="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" as="script">
    <link rel="preload" href="/scripts/main.js?v=20211217" as="script">
    <link rel="preload" href="/scripts/dark.js?v=20211217" as="script">
    <link rel="preload" href="/font/Oswald-Regular.ttf" as="font" crossorigin>
    <link rel="preload" href="https://at.alicdn.com/t/font_327081_1dta1rlogw17zaor.woff" as="font" crossorigin>
    <!-- algolia -->
    
    <!-- 百度统计  -->
    
    <!-- 谷歌统计  -->
    
<meta name="generator" content="Hexo 6.2.0"></head>

    <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js"></script>
    <script type="text/javascript">
        if (typeof window.$ == undefined) {
            console.warn('jquery load from jsdelivr failed, will load local script')
            document.write('<script src="/lib/jquery.min.js" />')
        }
    </script>
    
        <body class="post-body">
    
        <!-- header -->
        <header class="header header-mobile">
    <!-- top read progress line -->
    <div class="header-element">
        <div class="read-progress"></div>
    </div>
    <!-- sidebar menu button -->
    <div class="header-element">
        
            <div class="header-sidebar-menu">
        
            
                <div style="padding-left: 1px;">&#xe775;</div>
            
        </div>
    </div>
    <!-- header actions -->
    <div class="header-actions">
        <!-- theme mode switch button -->
        <span class="header-theme-btn header-element">
            <i class="fas fa-adjust"></i>
        </span>
        <!-- back to home page text -->
        <span class="home-link header-element">
            <a href=/>PityBug's Studio.</a>
        </span>
    </div>
    <!-- toggle banner for post layout -->
    
        
            <div class="banner">
        
            <div class="blog-title header-element">
                <a href="/">PityBug&#39;s Studio.</a>
            </div>
            <div class="post-title header-element">
                <a href="#" class="post-name">【RL】PPO以及更新神经网络RNN</a>
            </div>
        </div>
    
</header>

        <!-- fixed footer -->
        <footer class="footer-fixed">
    <!-- back to top button -->
    <div class="footer-fixed-element">
        
            <div class="back-top back-top-hidden">
        
        
            <div>&#xe639;</div>
        
        </div>
    </div>
</footer>

        <!-- wrapper -->
        <div class="wrapper">
            <div class="site-intro" style="







    height:50vh;

">
    
    <!-- 主页  -->
    
        
    <!-- 404页  -->
    
    <div class="site-intro-placeholder"></div>
    <div class="site-intro-img" style="background-image: url(/intro/post-bg.jpg)"></div>
    <div class="site-intro-meta">
        <!-- 标题  -->
        <h1 class="intro-title">
            <!-- 主页  -->
            
                【RL】PPO以及更新神经网络RNN
            <!-- 404 -->
            
        </h1>
        <!-- 副标题 -->
        <p class="intro-subtitle">
            <!-- 主页副标题  -->
            
                
            <!-- 404 -->
            
        </p>
        <!-- 文章页 meta -->
        
            <div class="post-intros">
                <!-- 文章页标签  -->
                
                    <div class= post-intro-tags >
    
    
</div>

                
                <!-- 文章字数统计 -->
                
                    <div class="post-intro-read">
                        <span>字数统计: <span class="post-count word-count">3.1k</span>阅读时长: <span class="post-count reading-time">14 min</span></span>
                    </div>
                
                <div class="post-intro-meta">
                    <!-- 撰写日期 -->
                    <span class="iconfont-archer post-intro-calander">&#xe676;</span>
                    <span class="post-intro-time">2023/03/15</span>
                    <!-- busuanzi -->
                    
                        <span id="busuanzi_container_page_pv" class="busuanzi-pv">
                            <span class="iconfont-archer post-intro-busuanzi">&#xe602;</span>
                            <span id="busuanzi_value_page_pv"></span>
                        </span>
                    
                    <!-- 文章分享 -->
                    <span class="share-wrapper">
                        <span class="iconfont-archer share-icon">&#xe71d;</span>
                        <span class="share-text">Share</span>
                        <ul class="share-list">
                            <li class="iconfont-archer share-qr" data-type="qr">&#xe75b;
                                <div class="share-qrcode"></div>
                            </li>
                            <li class="iconfont-archer" data-type="weibo">&#xe619;</li>
                            <li class="iconfont-archer" data-type="qzone">&#xe62e;</li>
                            <li class="iconfont-archer" data-type="twitter">&#xe634;</li>
                            <li class="iconfont-archer" data-type="facebook">&#xe67a;</li>
                        </ul>
                    </span>
                </div>
            </div>
        
    </div>
</div>

            <script>
  // get user agent
  function getBrowserVersions() {
    var u = window.navigator.userAgent
    return {
      userAgent: u,
      trident: u.indexOf('Trident') > -1, //IE内核
      presto: u.indexOf('Presto') > -1, //opera内核
      webKit: u.indexOf('AppleWebKit') > -1, //苹果、谷歌内核
      gecko: u.indexOf('Gecko') > -1 && u.indexOf('KHTML') == -1, //火狐内核
      mobile: !!u.match(/AppleWebKit.*Mobile.*/), //是否为移动终端
      ios: !!u.match(/\(i[^;]+;( U;)? CPU.+Mac OS X/), //ios终端
      android: u.indexOf('Android') > -1 || u.indexOf('Linux') > -1, //android终端或者uc浏览器
      iPhone: u.indexOf('iPhone') > -1 || u.indexOf('Mac') > -1, //是否为iPhone或者安卓QQ浏览器
      iPad: u.indexOf('iPad') > -1, //是否为iPad
      webApp: u.indexOf('Safari') == -1, //是否为web应用程序，没有头部与底部
      weixin: u.indexOf('MicroMessenger') == -1, //是否为微信浏览器
      uc: u.indexOf('UCBrowser') > -1, //是否为android下的UC浏览器
    }
  }
  var browser = {
    versions: getBrowserVersions(),
  }
  console.log('userAgent: ' + browser.versions.userAgent)

  // callback
  function fontLoaded() {
    console.log('font loaded')
    if (document.getElementsByClassName('site-intro-meta')) {
      document
        .getElementsByClassName('intro-title')[0]
        .classList.add('intro-fade-in')
      document
        .getElementsByClassName('intro-subtitle')[0]
        .classList.add('intro-fade-in')
      var postIntros = document.getElementsByClassName('post-intros')[0]
      if (postIntros) {
        postIntros.classList.add('post-fade-in')
      }
    }
  }

  // UC不支持跨域，所以直接显示
  function asyncCb() {
    if (browser.versions.uc) {
      console.log('UCBrowser')
      fontLoaded()
    } else {
      WebFont.load({
        custom: {
          families: ['Oswald-Regular'],
        },
        loading: function () {
          // 所有字体开始加载
          // console.log('font loading');
        },
        active: function () {
          // 所有字体已渲染
          fontLoaded()
        },
        inactive: function () {
          // 字体预加载失败，无效字体或浏览器不支持加载
          console.log('inactive: timeout')
          fontLoaded()
        },
        timeout: 5000, // Set the timeout to two seconds
      })
    }
  }

  function asyncErr() {
    console.warn('script load from CDN failed, will load local script')
  }

  // load webfont-loader async, and add callback function
  function async(u, cb, err) {
    var d = document,
      t = 'script',
      o = d.createElement(t),
      s = d.getElementsByTagName(t)[0]
    o.src = u
    if (cb) {
      o.addEventListener(
        'load',
        function (e) {
          cb(null, e)
        },
        false
      )
    }
    if (err) {
      o.addEventListener(
        'error',
        function (e) {
          err(null, e)
        },
        false
      )
    }
    s.parentNode.insertBefore(o, s)
  }

  var asyncLoadWithFallBack = function (arr, success, reject) {
    var currReject = function () {
      reject()
      arr.shift()
      if (arr.length) async(arr[0], success, currReject)
    }

    async(arr[0], success, currReject)
  }

  asyncLoadWithFallBack(
    [
      'https://cdn.jsdelivr.net/npm/webfontloader@1.6.28/webfontloader.min.js',
      'https://cdn.bootcss.com/webfont/1.6.28/webfontloader.js',
      "/lib/webfontloader.min.js",
    ],
    asyncCb,
    asyncErr
  )
</script>

            <img class="loading" src="/assets/loading.svg" style="display: block; margin: 6rem auto 0 auto; width: 6rem; height: 6rem;" />
            <div class="container container-unloaded">
                <main class="main post-page">
    <article class="article-entry">
        <h1 id="状态价值函数v_pi和动作价值函数q_pi的关系">状态价值函数<span
class="math inline">\(V_{\pi}\)</span>和动作价值函数<span
class="math inline">\(Q_{\pi}\)</span>的关系</h1>
<ul>
<li><p><strong>状态价值函数</strong>:从状态<span
class="math inline">\(s\)</span>出发遵循策略<span
class="math inline">\(\pi\)</span>能获得的期望回报</p>
<p><span class="math display">\[
\begin{aligned}
    V_{\pi}(s)&amp;=\mathbb E [G_{t}|S_{t}=s]\\
    &amp;=\mathbb E [R_{t+1}+\gamma G_{t+1}|S_{t}=s]\\
    &amp;=\mathbb E [R_{t+1}+\gamma V_{\pi}(S_{t+1})|S_{t}=s]\\
    &amp;=\mathbb E [R_{t+1}|S_{t}=s]+\gamma \mathbb E
[G_{t+1}|S_{t}=s]\\
    &amp;=\mathbb E [R_{t+1}|S_{t}=s]+\gamma \mathbb E
[V_{\pi}(S_{t+1})|S_{t}=s]
\end{aligned}
\]</span> 展开理解</p>
<hr />
<ul>
<li><p><span class="math inline">\(G_{t}\)</span></p>
<ul>
<li><p>这里的<span class="math inline">\(G_{t}\)</span>是指在<span
class="math inline">\(t\)</span>时刻即时奖励和所有持久奖励等一切奖励的加权和</p></li>
<li><p>引入折扣因子（奖惩因子）<span
class="math inline">\(\gamma\)</span>，表示随着时间越往后回报率越低（对于当前的贡献奖励越低）</p></li>
<li><p>通俗地理解为越往后，越会有更多或更重要G_的因素成就更后面的好事，总不能所有好事都百分百归功于最开头选择的这个状态/决策</p></li>
</ul>
<p><span class="math display">\[
\begin{aligned}
    G_{t}&amp;=R_{t+1}+\gamma R_{t+1}+\gamma^2 R_{t+1}+\gamma^3
R_{t+1}\\
    &amp;=R_{t+1}+\gamma( R_{t+1}+\gamma R_{t+1}+\gamma^2 R_{t+1})\\
    &amp;=R_{t+1}+\gamma G_{t+1}
\end{aligned}
\]</span></p></li>
<li><p>即时奖励：<span class="math inline">\(\mathbb E
[R_{t+1}|S_{t}=s]=R(s)\)</span></p></li>
<li><p>持久奖励: <span class="math inline">\(\gamma \mathbb E
[V_{\pi}(S_{t+1})|S_{t}=s]\)</span></p></li>
<li><p>持久奖励推导：推导第2行到第3行 <span class="math display">\[
\begin{aligned}
\mathbb E [G_{t+1}|S_{t}=s]&amp;=\sum G_{t+1}P\{G_{t+1}|S_{t}=s\} \\
                &amp;=\sum G_{t+1}\sum_{s&#39;}P\{
G_{t+1}|S_{t+1}=s&#39;,S_{t}=s\}P\{S_{t+1}=s&#39;|S_{t}=s\}\\
                &amp;=\sum_{s&#39;}\sum G_{t+1}P\{
G_{t+1}|S_{t+1}=s&#39;,S_{t}=s\}P\{S_{t+1}=s&#39;|S_{t}=s\}\\
                &amp;=\sum_{s&#39;}\mathbb E[ G_{t+1}|
S_{t+1}=s&#39;,S_{t}=s]P\{S_{t+1}=s&#39;|S_{t}=s\}\\
                &amp;=\sum_{s&#39;}
V(S_{t+1})P\{S_{t+1}=s&#39;|S_{t}=s\}\\
                &amp;=\mathbb E[V(S_{t+1})|S_{t}=s]
\end{aligned}
\]</span></p>
<ul>
<li><strong>疑问？</strong>：<span class="math inline">\(\mathbb E[
G_{t+1}| S_{t+1}=s&#39;,S_{t}=s]?=\mathbb E[ G_{t+1}|
S_{t+1}=s&#39;]\)</span></li>
<li>1-&gt;2: 概率公式推导,这里不再赘述</li>
</ul></li>
<li><p>得到贝尔曼方程： <span class="math display">\[
V(s)=R(s)+\gamma\sum_{s&#39; \in S}P(s&#39;|s)V(s&#39;)
\]</span> 注：这里公式做了部分简化</p></li>
</ul></li>
<li><p><strong>动作价值函数</strong>:对当前状态<span
class="math inline">\(s\)</span>依据策略<span
class="math inline">\(\pi\)</span>行动作<span
class="math inline">\(a\)</span>得到的期望回报 <span
class="math display">\[
\begin{aligned}
Q_{\pi}(s,a)&amp;=\mathbb E [G_{t}|S_{t}=s,A_{t}=a]\\
&amp;=\mathbb E [R_{t+1}+\gamma G_{t+1}|S_{t}=s,,A_{t}=a]\\
&amp;=\mathbb E [R_{t+1}+\gamma
Q_{\pi}(S_{t+1},A_{t+1})|S_{t}=s,,A_{t}=a]
\end{aligned}
\]</span></p>
<ul>
<li>此处2-&gt;3推导与<span class="math inline">\(V(s)\)</span>一致</li>
<li>该函数用于选取一个最优动作</li>
</ul></li>
<li><p>两个函数的直接关系如图：</p>
<figure>
<img
src="https://img-blog.csdnimg.cn/5bbf0a4065be4b5584277e28502f7a7a.png"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure></li>
<li><p>可视化状态之间的转移以及采取的动作</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/6ca0c2b4b623c690c60a749dc1b21291.png" alt="img" style="zoom:50%;" /></p></li>
<li><p>在使用策略<embed
src="https://latex.codecogs.com/gif.latex?%5Cpi" />时，<strong>状态<span
class="math inline">\(s\)</span>的价值等于在该状态下基于策略<span
class="math inline">\(\pi\)</span>采取所有动作的概率与相应的价值相乘再求和的结果</strong>
<span class="math display">\[
V_{\pi}(s)=\sum_{a\in A}\pi(a|s)Q_{\pi}(s,a)
\]</span> <strong>疑问？</strong>注:这里的<span
class="math inline">\(\pi\)</span>指策略的概率函数<span
class="math inline">\(P_{\pi}\)</span></p></li>
<li><p>而使用策略<embed
src="https://latex.codecogs.com/gif.latex?%5Cpi" />时，在状态<span
class="math inline">\(s\)</span>下采取动作<span
class="math inline">\(a\)</span>的价值如下（动作价值） <span
class="math display">\[
Q_{\pi}(s,a)=R(s,a)+\gamma\sum_{s&#39; \in
S}P(s&#39;|s,a)V_{\pi}(s&#39;)
\]</span> 注：这里仿照的是<span
class="math inline">\(V(s)\)</span>的贝尔曼方程，这里的P是状态转移概率（对应图中）</p>
<ul>
<li>可以参考以下推导公式</li>
<li><figure>
<embed
src="https://latex.codecogs.com/gif.latex?%5Cbegin%7Baligned%7D%20Q_%5Cpi%20%28s%2Ca%29%20%26%3D%20E%5BG_t%7CS_t%20%3D%20t%2CA_t%20%3D%20a%5D%20%5C%5C%26%3D%20E%5BR_%7Bt+1%7D%20+%20%5Cgamma%20G_%7Bt+1%7D%20%7C%20S_t%20%3Ds%2CA_t%20%3D%20a%5D%20%5C%5C%26%3D%20E%5BR_%7Bt+1%7D%7CS_t%20%3D%20s%2CA_t%20%3D%20a%5D%20+%20%5Cgamma%20E%5B%20G_%7Bt+1%7D%20%7C%20S_t%20%3Ds%2CA_t%20%3D%20a%5D%20%5C%5C%26%3D%20R%28s%2Ca%29%20+%20%5Cgamma%20%5Csum_%7Bs%27%7D%5E%7B%7D%20V_%5Cpi%20%28S_%7Bt+1%7D%29%20P%5BS_%7Bt+1%7D%20%3D%20s%27%20%7CS_t%20%3Ds%2CA_t%20%3D%20a%20%5D%20%5C%5C%26%3D%20R%28s%2Ca%29%20+%20%5Cgamma%20%5Csum_%7Bs%27%7D%5E%7B%7D%20P_%7Bss%27%7D%5E%7Ba%7DV_%5Cpi%20%28s%27%29%20%5Cend%7Baligned%7D" />
<figcaption aria-hidden="true">img</figcaption>
</figure></li>
</ul></li>
<li><p>根据以上两个式子推导出马尔可夫决策的贝尔曼方程 <span
class="math display">\[
\begin{aligned}
V_{\pi}(s)&amp;=\sum_{a\in A}\pi(a|s)\Bigg[R(s,a)+\gamma\sum_{s&#39; \in
S}P(s&#39;|s,a)V_{\pi}(s&#39;) \Bigg]\\
Q_{\pi}(s,a)&amp;=R(s,a)+\gamma\sum_{s&#39; \in
S}P(s&#39;|s,a)\Bigg[\sum_{a\in A}\pi(a|s’)Q_{\pi}(s&#39;,a)\Bigg]
\end{aligned}
\]</span></p></li>
<li><p>以上关系推导过程参考以下图片</p>
<figure>
<img
src="https://img-blog.csdnimg.cn/ab200b2773a547bfa48e639956c52ca0.jpeg"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure></li>
<li><p>思考：</p>
<ul>
<li>这里的递推关系其实</li>
<li>与我们想象中的递推关系有点出入<span
class="math inline">\(dp[i]=f(dp[i+1])\)</span></li>
<li>需要呈现<span
class="math inline">\(dp[i]=f(dp[i-1])\)</span>的形式？？？</li>
</ul></li>
</ul>
<h1
id="ppo改进历程策略价值函数改进">PPO改进历程（策略价值函数改进）</h1>
<ul>
<li><p><strong>策略梯度</strong></p>
<ul>
<li><p>这里我理解的策略应该是动作选择策略，指参数为<span
class="math inline">\(\theta\)</span>的策略<span
class="math inline">\(\pi_{\theta}\)</span>接收到状态<span
class="math inline">\(s\)</span>后，输出一个动作概率分布</p></li>
<li><p>可以形式化表达函数为 <span class="math display">\[
a=\pi_{\theta}(s)
\]</span></p></li>
<li><p>往后的步骤：在动作概率分布中<strong>采样动作</strong>，执行动作(形成<strong>运动轨迹<span
class="math inline">\(\tau\)</span></strong>)，得到奖励<span
class="math inline">\(r\)</span>(这里的奖励需要做评价)，跳到下一个状态<span
class="math inline">\(s&#39;\)</span></p></li>
<li><p>该算法大量时间耗费在采用工作：当策略<span
class="math inline">\(\pi\)</span>的参数更新后，这些样本不能继续被使用，还要重新使用策略<span
class="math inline">\(\pi&#39;\)</span>与环境互动收集数据</p></li>
<li><p>神经网络角度：</p>
<ul>
<li>这里<span
class="math inline">\(\theta\)</span>是策略的一个参数，我们需要像训练神经网络那样，定义损失函数，通过损失函数梯度优化参数<span
class="math inline">\(\theta\)</span>,得到更好的策略</li>
<li>在此我们只需要定义一个目标优化函数（正向传播产生动作，然后动作在环境中产生奖励值，通过奖励值求和产生评价函数），对该函数做梯度上升，同样去优化参数<span
class="math inline">\(\theta\)</span></li>
</ul></li>
<li><p>运动轨迹 <span class="math display">\[
\tau=(s_1,a_1,r_1,s_2,a_2,r_2,s_3,a_3,r_3,...,s_t,a_t,r_t)
\]</span> <strong>疑问？</strong>：这里需要控制<span
class="math inline">\(t\)</span>吗？</p></li>
<li><p>根据以上轨迹，我们可以获得这条轨迹的概率</p>
<ul>
<li><p>动作概率分布<span
class="math inline">\(p_{\theta}(a_t|s_t)\)</span></p></li>
<li><p>状态概率分布<span
class="math inline">\(p(s_{t+1}|s_t,a_t)\)</span></p></li>
<li><p>轨迹<span class="math inline">\(\tau\)</span>概率如下 <span
class="math display">\[
\begin{aligned}
p_{\theta}(\tau)&amp;=p(s_1)p_{\theta}(a_1|s_1)p(s_2|s_1,a_1)p_{\theta}(a_2|s_2)p(s_3|s_2,a_2)\\
&amp;=p(s_1)\prod_{t=1}^T p_{\theta}(a_t|s_t)p(s_{t+1}|s_t,a_t)
\end{aligned}
\]</span></p></li>
</ul></li>
<li><p>这里的策略函数可以看作综合评价动作和状态，以一个期望值作为评价标准</p></li>
</ul></li>
<li><p><strong>策略价值函数</strong>：对所有<span
class="math inline">\(\tau\)</span>出现的概率与对应的奖励进行加权最后求和</p>
<p>​ (看着好像很简单？？) <span class="math display">\[
\bar{R}_{\theta}=\sum_{\tau}R(\tau)p_{\theta}(\tau)=\mathbb E_{\tau~
p_{\theta}}[R(\tau)]\\
R(\tau)=\sum_{t=1}^T r_t
\]</span></p>
<ul>
<li><p>整个期望奖励可视化表示如下：</p>
<p><img src="https://img-blog.csdnimg.cn/756685e2f07b494b99bc97f4ce0f4bf9.png" alt="img" style="zoom: 25%;" /></p></li>
<li><p>梯度计算 <span class="math display">\[
\nabla \bar{R}_{\theta}=\sum_{\tau} R(\tau)\nabla p_{\theta}(\tau)
\]</span></p>
<ul>
<li><p>根据一常用的技巧 <span class="math display">\[
\nabla f(x)=f(x)\nabla \log f(x)
\]</span></p></li>
<li><p>进一步推导为 <span class="math display">\[
\begin{aligned}
\nabla \bar{R}_{\theta}&amp;=\sum_{\tau} R(\tau)\nabla
p_{\theta}(\tau)\\
&amp;=\sum_{\tau}R(\tau)p_{\theta}(\tau)\nabla \log p_{\theta}(\tau)\\
&amp;=\sum_{\tau}\Big[R(\tau)\nabla \log p_{\theta}(\tau)\Big]
p_{\theta}(\tau)\\
&amp;=\mathbb E_{\tau \sim p_{\theta}(\tau)}[R(\tau) \nabla \log
p_{\theta}(\tau)]
\end{aligned}
\]</span></p></li>
</ul></li>
<li><p>MC近似计算</p>
<p>近似计算取平均如下： <span class="math display">\[
\begin{aligned}
\mathbb E_{\tau \sim p_{\theta}(\tau)}[R(\tau) \nabla \log
p_{\theta}(\tau)]&amp;\approx \frac{1}{N}\sum_{n=1}^N R(\tau^n) \nabla
\log p_{\theta}(\tau^n)\\
&amp;=\frac{1}{N}\sum_{n=1}^N \sum_{t=1}^{T_n} R(\tau^n) \nabla \log
p_{\theta}(a_{t}^n|s_{t}^n)
\end{aligned}
\]</span></p>
<ul>
<li><p>1-&gt;2推导</p>
<ul>
<li>取对数</li>
</ul>
<p><span class="math display">\[
\log p_{\theta}(\tau)=\log (s_1)+\sum_{t=1}^{T_n}(\log
p(s_{t+1}|s_t,a_t)+\log p_{\theta}(a_t|s_t))
\]</span></p>
<ul>
<li>对<span class="math inline">\(\theta\)</span>求梯度 <span
class="math display">\[
\nabla \log p_{\theta}(\tau)=\sum_{t=1}^{T_n}\nabla \log
p_{\theta}(a_t|s_t)
\]</span></li>
</ul></li>
</ul></li>
</ul></li>
<li><p><strong>重要性采样</strong></p>
<ul>
<li><p>解决采样花费大量时间的问题</p></li>
<li><p><strong>将同策略模式转变成异策略模式</strong></p>
<ul>
<li>同一个策略采样的数据可以作多次更新，受单一采样数据约束</li>
<li>使用<span
class="math inline">\(\theta&#39;\)</span>采样到的数据训练<span
class="math inline">\(\theta\)</span>，并且可,以反复使用该采样数据，执行多次梯度上升（不需要反复采样）</li>
<li>对梯度加上重要性权重<span
class="math inline">\(\frac{p_{\theta}(\tau)}{p_{\theta&#39;}(\tau)}\)</span></li>
</ul></li>
<li><p>梯度公式更新为 $$</p>
<span class="math display">\[\begin{aligned}
\nabla \bar{R}_{\theta}&amp;=\mathbb E_{\tau \sim
p_{\theta}(\tau)}[R(\tau) \nabla \log p_{\theta}(\tau)]\\
&amp;=\sum_{\tau}\Big[R(\tau)\nabla \log p_{\theta}(\tau)\Big]
p_{\theta}(\tau)\\
&amp;=\sum_{\tau}\Big[\frac{p_{\theta}(\tau)}{p_{\theta&#39;}(\tau)}R(\tau)\nabla
\log p_{\theta}(\tau)\Big]p_{\theta&#39;}(\tau) \\
&amp;=\mathbb E_{\tau \sim
p_{\theta&#39;}(\tau)}[\frac{p_{\theta}(\tau)}{p_{\theta&#39;}(\tau)}R(\tau)
\nabla \log p_{\theta}(\tau)]

\end{aligned}\]</span>
<p>$$</p></li>
</ul></li>
<li><p><strong>A2C</strong></p>
<ul>
<li><p>加入基准线<span class="math inline">\(b\)</span>（不依赖动作<span
class="math inline">\(a\)</span>），避免</p>
<ul>
<li>所有动作都是正奖励</li>
<li>出现较大的方差</li>
</ul></li>
<li><p>梯度更新 <span class="math display">\[
\begin{aligned}
\mathbb E_{\tau \sim p_{\theta}(\tau)}[R(\tau) \nabla \log
p_{\theta}(\tau)]&amp;\approx \frac{1}{N}\sum_{n=1}^N \sum_{t=1}^{T_n}
R(\tau^n-b) \nabla \log p_{\theta}(a_{t}^n|s_{t}^n)
\end{aligned}
\]</span></p></li>
<li><p>基准线选择</p>
<ul>
<li>奖励均值 <span class="math display">\[
b=\frac{1}{T}\sum_{t=0}^T R_{t}(\tau)
\]</span></li>
</ul></li>
</ul></li>
<li><p>状态价值函数 <span class="math display">\[
    b=V_{\pi}(s_{t})
    \]</span></p></li>
<li><p><strong>优势函数定义</strong></p>
<ul>
<li><p><span class="math inline">\(A^{\theta}(s_t,a_t)\)</span></p>
<ul>
<li>正：增加概率</li>
<li>负：减少概率</li>
</ul></li>
<li><p>$A_{}(s,a)=Q_{}(s,a)-V_{}(s) $</p>
<ul>
<li>在选择一个动作时，根据该动作相对于特定状态下其他可用动作的执行情况来选择，而不是根据该动作的绝对值(<span
class="math inline">\(Q\)</span>函数估计)</li>
</ul></li>
<li><p>仿照上述目标优化函数，更新梯度更新公式 $$</p>
<span class="math display">\[\begin{aligned}
\nabla \bar{R}_{\theta}&amp;=\mathbb E_{\tau \sim
p_{\theta}(\tau)}[A^{\theta}(s_t,a_t)\nabla \log p_{\theta}(\tau)]\\
&amp;=\mathbb E_{\tau \sim
p_{\theta&#39;}(\tau)}[\frac{p_{\theta}(s_t,a_t)}{p_{\theta&#39;}(s_t,a_t)}A^{\theta&#39;}(s_t,a_t)\nabla
\log p_{\theta}(\tau)]\\
&amp;=\mathbb E_{(s_t,a_t)  \sim
p_{\theta&#39;}}[\frac{p_{\theta}(s_t,a_t)}{p_{\theta&#39;}(s_t,a_t)}A^{\theta&#39;}(s_t,a_t)\nabla
\log p_{\theta}(a_{t}^n |s_t^n)]\\
&amp;=\mathbb E_{(s_t,a_t)  \sim
p_{\theta&#39;}}[\frac{p_{\theta}(a_t|s_t)p_{\theta}(s_t)}{p_{\theta&#39;}(a_t|s_t)p_{\theta&#39;}(s_t)}A^{\theta&#39;}(s_t,a_t)\nabla
\log p_{\theta}(a_{t}^n |s_t^n)]\\
&amp;=\mathbb E_{(s_t,a_t)  \sim
p_{\theta&#39;}}[\frac{p_{\theta}(a_t|s_t)}{p_{\theta&#39;}(a_t|s_t)}A^{\theta&#39;}(s_t,a_t)\nabla
\log p_{\theta}(a_{t}^n |s_t^n)]\\


\end{aligned}\]</span>
<p>$$</p>
<ul>
<li>这里需要假设<span
class="math inline">\(p_{\theta}(s_t)=p_{\theta&#39;}(s_t)\)</span>,这里<span
class="math inline">\(s_t\)</span>概率难以确定，直接忽略，对于图像概率不好处理</li>
<li>对于动作的条件概率是好算的，根据原来的策略概率计算即可</li>
</ul></li>
<li><p>反推回目标优化函数</p>
<ul>
<li>利用前面的对应公式推导</li>
</ul>
<p><span class="math display">\[
J^{\theta&#39;}(\theta)==\mathbb E_{(s_t,a_t)  \sim
p_{\theta&#39;}}[\frac{p_{\theta}(a_t|s_t)}{p_{\theta&#39;}(a_t|s_t)}A^{\theta&#39;}(s_t,a_t)]\\
\]</span></p></li>
</ul></li>
<li><p><strong>TRPO </strong></p>
<ul>
<li><p>加入KL散度</p>
<ul>
<li><p>直观感受</p>
<figure>
<img
src="https://img-blog.csdnimg.cn/img_convert/046b440033c8296f2f9b0f1bf5c3190e.png"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure></li>
<li><p><strong>KL散度=交叉熵-shannon熵</strong> $$</p>
<span class="math display">\[\begin{aligned}
D_{KL}(p||q)&amp;=H(p,q)-H(p)\\
&amp;=-\sum p(x) \log q(x)+\sum p(x) \log p(x)\\
&amp;=-\sum p(x) \log \frac{q(x)}{p(x)}\\
&amp;=\sum p(x)\log \frac{q(x)}{p(x)}

\end{aligned}\]</span>
<p>$$</p></li>
<li><p>KL散度性质：</p>
<ul>
<li><span class="math inline">\(D_{KL} &gt;=0\)</span> <span
class="math display">\[
\begin{aligned}
-D_{KL}(p||q)
&amp;=\sum p(x) \log \frac{q(x)}{p(x)}\\
&amp; \le p(x)\frac{q(x)}{p(x)}\\
&amp;=\log 1 \\
&amp;=0
\end{aligned}
\]</span></li>
</ul></li>
</ul></li>
<li><p>解决分布相差大问题</p></li>
<li><p>解决步长难以确定问题</p></li>
<li><p>增加KL约束</p>
<ul>
<li><p>目标优化问题变为 <span class="math display">\[
J^{\theta&#39;}_{TRPO}(\theta)==\mathbb E_{(s_t,a_t)  \sim
p_{\theta&#39;}}[\frac{p_{\theta}(a_t|s_t)}{p_{\theta&#39;}(a_t|s_t)}A^{\theta&#39;}(s_t,a_t)],KL(\theta,\theta&#39;)&lt;\delta\\
\]</span></p></li>
<li><p>该约束条件使得两个分布相差尽可能小，从而也可以避免步长过大</p></li>
</ul></li>
<li><p>加入KL散度约束后，计算难度加大</p></li>
</ul></li>
<li><p><strong>ppo</strong></p>
<ul>
<li><p>ppo继承TRPO优点，限制new
policy的更新幅度，对较大的步长不太敏感</p></li>
<li><p>近端策略优化惩罚</p>
<ul>
<li><p>相当于给该问题加入正则化项，要求学习到的<span
class="math inline">\(\theta\)</span>和<span
class="math inline">\(\theta&#39;\)</span>越相似越好</p></li>
<li><p><strong>得到PPO优化公式为：</strong> <span
class="math display">\[
J^{\theta&#39;}_{PPO}(\theta)=J^{\theta&#39;}(\theta)-\beta
KL(\theta,\theta&#39;)
\]</span></p></li>
</ul></li>
</ul></li>
<li><p><span
class="math inline">\(\beta\)</span>为超参数，作自适应惩罚</p></li>
<li><p>需要设置散度最大值<span
class="math inline">\(KL_{max}\)</span>，最小值<span
class="math inline">\(KL_{min}\)</span>,保证惩罚效果</p></li>
<li><p><strong>近端策略优化裁剪</strong></p>
<ul>
<li><p>简化KL散度，得到目标函数应该为 <span class="math display">\[
  J^{\theta&#39;}_{PPO}(\theta)\approx
\sum_{(s_t,a_t)}min(\frac{p_{\theta}(a_t|s_t)}{p_{\theta&#39;}(a_t|s_t)}A^{\theta&#39;}(s_t,a_t),clip(\frac{p_{\theta}(a_t|s_t)}{p_{\theta&#39;}(a_t|s_t)},1-\epsilon,1+\epsilon)A^{\theta&#39;}(s_t,a_t))
  \]</span></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">// ratios即为重要性权重，exp代表求期望，括号里的environment_log_probs代表用于与环境交互的策略</span><br><span class="line">ratios = torch.exp(log_probs - environment_log_probs)</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">// 分别用sur_1、sur_2来计算公式的两部分</span><br><span class="line">// 第一部分是重要性权重乘以优势函数</span><br><span class="line">sur_1 = ratios * advs</span><br><span class="line"> </span><br><span class="line">// 第二部分是具体的裁剪过程</span><br><span class="line">sur_2 = torch.clamp(ratios, <span class="number">1</span> - clip_eps, <span class="number">1</span> + clip_eps) * advs</span><br><span class="line"> </span><br><span class="line">// 最终看谁更小则取谁</span><br><span class="line">clip_loss = -torch.<span class="built_in">min</span>(sur_1,sur_2).mean()</span><br></pre></td></tr></table></figure></li>
<li><p>第二部分理解</p>
<ul>
<li>对概率比进行裁剪，保证两个概率分布尽可能相似
<ul>
<li>好动作（<span class="math inline">\(A&gt;0\)</span>）：增大<span
class="math inline">\(p_{\theta}\)</span>,概率比不大于<span
class="math inline">\(1+\epsilon\)</span></li>
<li>不是好动作(<span class="math inline">\(A&lt;0\)</span>)：减小<span
class="math inline">\(p_{\theta}\)</span>,概率比不小于<span
class="math inline">\(1-\epsilon\)</span></li>
</ul></li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/1798baf5dba54e21a19508e82d407a8a.png" alt="1798baf5dba54e21a19508e82d407a8a.png" style="zoom:50%;" /></p>
<ul>
<li>整个式子理解
<ul>
<li>好动作步长不会太大</li>
<li>不好动作步长不会太小</li>
<li><figure>
<img
src="https://img-blog.csdnimg.cn/img_convert/0bb3ab43b467ce1071d28a89537abc9c.png"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure></li>
<li><span class="math inline">\(A&gt;0,ratio&gt;1+\epsilon:(1+\epsilon
)·A\)</span></li>
<li><span
class="math inline">\(A&gt;0,ratio&lt;1-\epsilon:ratio·A\)</span></li>
<li><span
class="math inline">\(A&lt;0,ratio&gt;1+\epsilon:ratio·A\)</span></li>
<li><span class="math inline">\(A&lt;0,ratio&lt;1-\epsilon:(1-\epsilon
)·A\)</span></li>
</ul></li>
</ul></li>
</ul></li>
</ul>

    </article>
    <!-- license -->
    
        <div class="license-wrapper">
            <p>原文作者：<a href="https://Klc1006.github.io">Klc</a>
            <p>原文链接：<a href="https://klc1006.github.io/2023/03/15/%E3%80%90RL%E3%80%91PPO/">https://klc1006.github.io/2023/03/15/%E3%80%90RL%E3%80%91PPO/</a>
            <p>发表日期：<a href="https://klc1006.github.io/2023/03/15/%E3%80%90RL%E3%80%91PPO/">March 15th 2023, 5:02:53 pm</a>
            <p>更新日期：<a href="https://klc1006.github.io/2023/03/15/%E3%80%90RL%E3%80%91PPO/">March 16th 2023, 8:39:57 pm</a>
            <p>版权声明：本文采用<a rel="license noopener" target="_blank" href="http://creativecommons.org/licenses/by-nc/4.0/">知识共享署名-非商业性使用 4.0 国际许可协议</a>进行许可</p>
        </div>
    
    <!-- paginator -->
    <ul class="post-paginator">
        <li class="next">
            
        </li>
        <li class="previous">
            
                <div class="prevSlogan">Previous Post</div>
                <a href="/2023/03/08/leetcodet%E9%A2%98%E8%A7%A3%E7%AC%94%E8%AE%B0/" title="【Leetcode】题解笔记">
                    <div class="prevTitle">【Leetcode】题解笔记</div>
                </a>
            
        </li>
    </ul>
    <!-- comment -->
    
        <div class="post-comment">
            <!-- 来必力 City 版安装代码 -->


            

            

            

            <!-- utteranc评论 -->


            <!-- partial('_partial/comment/changyan') -->
            <!--PC版-->


            
            

            

        </div>
    
    <!-- timeliness note -->
    <!-- idea from: https://hexo.fluid-dev.com/posts/hexo-injector/#%E6%96%87%E7%AB%A0%E6%97%B6%E6%95%88%E6%80%A7%E6%8F%90%E7%A4%BA -->
    
    <!-- Mathjax -->
    
        
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
            }
        };
    </script>

    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>


    
</main>

                <!-- profile -->
                
            </div>
            <footer class="footer footer-unloaded">
    <!-- social  -->
    
        <div class="social">
            
    
        
            
                <a href="mailto:1172485065@qq.com" class="iconfont-archer email" title=email ></a>
            
        
    
        
            
                <a href="https://github.com/Klc1006" class="iconfont-archer github" target="_blank" title=github></a>
            
        
    
        
            
                <span class="iconfont-archer wechat" title=wechat>
                    
                    <img class="profile-qr" src="/assets/wechatqr.jpg" />
                </span>
            
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    


        </div>
    
    <!-- powered by Hexo  -->
    <div class="copyright">
        <span id="hexo-power">Powered by <a href="https://hexo.io/" target="_blank">Hexo</a></span><span class="iconfont-archer power">&#xe635;</span><span id="theme-info">theme <a href="https://github.com/fi3ework/hexo-theme-archer" target="_blank">Archer</a></span>
    </div>
    <!-- website approve for Chinese user -->
    
    <!-- 不蒜子  -->
    
        <div class="busuanzi-container">
            
             
                <span id="busuanzi_container_site_pv">PV: <span id="busuanzi_value_site_pv"></span> :)</span>
            
        </div>
    	
</footer>

        </div>
        <!-- toc -->
        
            <div class="toc-wrapper toc-wrapper-loding" style=







    top:50vh;

>
                <div class="toc-catalog">
                    <span class="iconfont-archer catalog-icon">&#xe613;</span><span>CATALOG</span>
                </div>
                <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%8A%B6%E6%80%81%E4%BB%B7%E5%80%BC%E5%87%BD%E6%95%B0v_pi%E5%92%8C%E5%8A%A8%E4%BD%9C%E4%BB%B7%E5%80%BC%E5%87%BD%E6%95%B0q_pi%E7%9A%84%E5%85%B3%E7%B3%BB"><span class="toc-number">1.</span> <span class="toc-text">状态价值函数\(V_{\pi}\)和动作价值函数\(Q_{\pi}\)的关系</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#ppo%E6%94%B9%E8%BF%9B%E5%8E%86%E7%A8%8B%E7%AD%96%E7%95%A5%E4%BB%B7%E5%80%BC%E5%87%BD%E6%95%B0%E6%94%B9%E8%BF%9B"><span class="toc-number">2.</span> <span class="toc-text">PPO改进历程（策略价值函数改进）</span></a></li></ol>
            </div>
        
        <!-- sidebar -->
        <div class="sidebar sidebar-hide">
    <ul class="sidebar-tabs sidebar-tabs-active-0">
        <li class="sidebar-tab-archives"><span class="iconfont-archer">&#xe67d;</span><span class="tab-name">Archive</span></li>
        <li class="sidebar-tab-tags"><span class="iconfont-archer">&#xe61b;</span><span class="tab-name">Tag</span></li>
        <li class="sidebar-tab-categories"><span class="iconfont-archer">&#xe666;</span><span class="tab-name">Cate</span></li>
    </ul>
    <div class="sidebar-content sidebar-content-show-archive">
        <div class="sidebar-panel-archives">
    <!-- 在 ejs 中将 archive 按照时间排序 -->
    
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
    
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
    
    
    
    
    <div class="total-and-search">
        <div class="total-archive">
        Total : 16
        </div>
        <!-- search  -->
        
    </div>
    
    <div class="post-archive">
    
        
            
            
            <div class="archive-year"> 2023 </div>
            <ul class="year-list">
            
        
        <li class="archive-post-item">
            <span class="archive-post-date">03/15</span>
            <a class="archive-post-title" href="/2023/03/15/%E3%80%90RL%E3%80%91PPO/">【RL】PPO以及更新神经网络RNN</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">03/08</span>
            <a class="archive-post-title" href="/2023/03/08/leetcodet%E9%A2%98%E8%A7%A3%E7%AC%94%E8%AE%B0/">【Leetcode】题解笔记</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">03/07</span>
            <a class="archive-post-title" href="/2023/03/07/cpp/">面向对象编程 OOP（cpp语言篇）</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">01/09</span>
            <a class="archive-post-title" href="/2023/01/09/%E3%80%90%E8%AE%A1%E5%9B%BE%E3%80%91hw6/">【计算机图形学】Assignment6 Mass Spring Simulation</a>
        </li>
    
        
            
            
                
                </ul>
            
            <div class="archive-year"> 2022 </div>
            <ul class="year-list">
            
        
        <li class="archive-post-item">
            <span class="archive-post-date">12/25</span>
            <a class="archive-post-title" href="/2022/12/25/%E3%80%90%E8%AE%A1%E5%9B%BE%E3%80%91hw5/">【计算机图形学】Assignment5 Bezier Curve</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">12/05</span>
            <a class="archive-post-title" href="/2022/12/05/%E3%80%90%E8%AE%A1%E5%9B%BE%E3%80%91hw4/">【计算机图形学】Assignment4 Ray Tracing</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">11/29</span>
            <a class="archive-post-title" href="/2022/11/29/%E3%80%90%E8%AE%A1%E5%9B%BE%E3%80%91hw3%20/">【计算机图形学】Assignment3 Lighting Texturing</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">10/26</span>
            <a class="archive-post-title" href="/2022/10/26/%E3%80%90%E8%AE%A1%E5%9B%BE%E3%80%91hw2/">【计算机图形学】Assignment2_Rasterization_ZBuffering</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">10/09</span>
            <a class="archive-post-title" href="/2022/10/09/%E3%80%90%E8%AE%A1%E5%9B%BE%E3%80%91hw1/">【计算机图形学】Assignment1 3D Transformation</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">06/09</span>
            <a class="archive-post-title" href="/2022/06/09/AI%20Course%2012/">【AI Course】PDDL解决规划问题</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">05/19</span>
            <a class="archive-post-title" href="/2022/05/19/AI%20Course%208/">【AI Course】KNN完成情感分类标签</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">05/07</span>
            <a class="archive-post-title" href="/2022/05/07/AI%20Course%207%20203/">【AI Course】朴素贝叶斯</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">04/28</span>
            <a class="archive-post-title" href="/2022/04/28/AI%20Course%206/">【AI Course】归结演绎推理</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">04/09</span>
            <a class="archive-post-title" href="/2022/04/09/AI%20Course3/">【AI Course】A*和 IDA*算法解决15-puzzle问题</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">03/02</span>
            <a class="archive-post-title" href="/2022/03/02/AI%20course%201_20337013/">【AI Course】一致代价实现最短路径</a>
        </li>
    
        
            
            
                
                </ul>
            
            <div class="archive-year"> 2021 </div>
            <ul class="year-list">
            
        
        <li class="archive-post-item">
            <span class="archive-post-date">11/15</span>
            <a class="archive-post-title" href="/2021/11/15/%E3%80%90%E8%AE%A1%E7%BB%84%E5%AE%9E%E9%AA%8C%E3%80%91%E5%8D%95%E5%91%A8%E6%9C%9FCPU/">【计组实验】单周期CPU</a>
        </li>
    
    </div>
</div>

        <div class="sidebar-panel-tags">
    <div class="sidebar-tags-name">
        
            <span class="sidebar-tag-name" data-tags="归结推理">
                <span class="iconfont-archer">&#xe606;</span>
                归结推理
            </span>
        
            <span class="sidebar-tag-name" data-tags="A*">
                <span class="iconfont-archer">&#xe606;</span>
                A*
            </span>
        
            <span class="sidebar-tag-name" data-tags="IDA*">
                <span class="iconfont-archer">&#xe606;</span>
                IDA*
            </span>
        
            <span class="sidebar-tag-name" data-tags="PDDL">
                <span class="iconfont-archer">&#xe606;</span>
                PDDL
            </span>
        
            <span class="sidebar-tag-name" data-tags="规划问题">
                <span class="iconfont-archer">&#xe606;</span>
                规划问题
            </span>
        
            <span class="sidebar-tag-name" data-tags="AI">
                <span class="iconfont-archer">&#xe606;</span>
                AI
            </span>
        
            <span class="sidebar-tag-name" data-tags="最短路径">
                <span class="iconfont-archer">&#xe606;</span>
                最短路径
            </span>
        
            <span class="sidebar-tag-name" data-tags="朴素贝叶斯">
                <span class="iconfont-archer">&#xe606;</span>
                朴素贝叶斯
            </span>
        
            <span class="sidebar-tag-name" data-tags="KNN">
                <span class="iconfont-archer">&#xe606;</span>
                KNN
            </span>
        
            <span class="sidebar-tag-name" data-tags="分类">
                <span class="iconfont-archer">&#xe606;</span>
                分类
            </span>
        
            <span class="sidebar-tag-name" data-tags="cpp">
                <span class="iconfont-archer">&#xe606;</span>
                cpp
            </span>
        
            <span class="sidebar-tag-name" data-tags="leetcode">
                <span class="iconfont-archer">&#xe606;</span>
                leetcode
            </span>
        
            <span class="sidebar-tag-name" data-tags="CPU">
                <span class="iconfont-archer">&#xe606;</span>
                CPU
            </span>
        
    </div>
    <div class="iconfont-archer sidebar-tags-empty">&#xe678;</div>
    <div class="tag-load-fail" style="display: none; color: #ccc; font-size: 0.6rem;">
        缺失模块，请参考主题文档进行安装配置：https://github.com/fi3ework/hexo-theme-archer#%E5%AE%89%E8%A3%85%E4%B8%BB%E9%A2%98
    </div> 
    <div class="sidebar-tags-list"></div>
</div>

        <div class="sidebar-panel-categories">
    <div class="sidebar-categories-name">
    
    </div>
    <div class="iconfont-archer sidebar-categories-empty">&#xe678;</div>
    <div class="sidebar-categories-list"></div>
</div>

    </div>
</div>

        <!-- site-meta -->
        <script>
    var siteMetaRoot = "/"
    if (siteMetaRoot === "undefined") {
        siteMetaRoot = '/'
    }
    var siteMeta = {
        url: "https://Klc1006.github.io",
        root: siteMetaRoot,
        author: "Klc"
    }
</script>

        <!-- import experimental options here -->
        <!-- Custom Font -->


        <!-- main func -->
        <script src="/scripts/main.js?v=20211217"></script>
        <!-- dark mode -->
        <script src="/scripts/dark.js?v=20211217"></script>
        <!-- fancybox -->
        <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js" defer></script>
        <!-- algolia -->
        
        <!-- busuanzi -->
        
            <script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script>
        
        <!-- CNZZ -->
        
        <!-- async load share.js -->
        
            <script src="/scripts/share.js?v=20211217" async></script>
        
        <!-- mermaid -->
        
            <script src='https://cdn.jsdelivr.net/npm/mermaid@8.11.0/dist/mermaid.min.js'></script>
            <script>
                if (window.mermaid) {
                    mermaid.initialize({theme: 'dark'});
                }
            </script>
        
    </body>
</html>
